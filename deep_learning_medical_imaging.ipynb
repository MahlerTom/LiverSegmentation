{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_medical_imaging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahlerTom/LiverSegmentation/blob/master/deep_learning_medical_imaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fIDrdOYNagd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_956uYk4lWcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "\n",
        "# Set some parameters\n",
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 512\n",
        "TRAIN_PATH = '..//TrainData'\n",
        "VAL_PATH = '..//ValData'\n",
        "\n",
        "# TEST_PATH = '../input/stage1_test/'\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6wr79MNldF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get train and test IDs\n",
        "# train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "# test_ids = next(os.walk(TEST_PATH))[1]\n",
        "train_ids = [ name[3:] for name in os.listdir(TRAIN_PATH + '//images') ]\n",
        "\n",
        "# Get and resize train images and masks\n",
        "images = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "labels = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH\n",
        "    img = imread(path + '/images/ct_' + id_, as_gray=True)\n",
        "    img = np.expand_dims(resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=2)\n",
        "    images[n] = img\n",
        "    mask = imread(path + '/masks/seg_' + id_, as_gray=True)\n",
        "    mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=2)\n",
        "#     np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
        "#     for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "#         mask_ = imread(path + '/masks/' + mask_file)[:,:,:IMG_CHANNELS]\n",
        "#         mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
        "#                                       preserve_range=True), axis=-1)\n",
        "#         mask = np.maximum(mask, mask_)\n",
        "    labels[n] = mask\n",
        "\n",
        "X_train = images\n",
        "Y_train = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPWTWbvJleRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_ids = [ name[3:] for name in os.listdir(VAL_PATH + '//images') ]\n",
        "\n",
        "# Get and resize test images\n",
        "X_val = np.zeros((len(val_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
        "sizes_val = []\n",
        "print('Getting and resizing val images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(val_ids), total=len(val_ids)):\n",
        "    path = VAL_PATH\n",
        "    img = imread(path + '/images/ct_' + id_, as_gray=True)\n",
        "    sizes_val.append([img.shape[0], img.shape[1]])\n",
        "    img = np.expand_dims(resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=2)\n",
        "    X_val[n] = img\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXlwF3WBlfeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle():\n",
        "    global images, labels\n",
        "    p = np.random.permutation(len(X_train))\n",
        "    images = X_train[p]\n",
        "    labels = Y_train[p]\n",
        "\n",
        "def next_batch(batch_s, iters):\n",
        "    if(iters == 0):\n",
        "        shuffle()\n",
        "    count = batch_s * iters\n",
        "    return images[count:(count + batch_s)], labels[count:(count + batch_s)]\n",
        "\n",
        "def deconv2d(input_tensor, filter_size, output_size, out_channels, in_channels, name, strides = [1, 1, 1, 1]):\n",
        "    dyn_input_shape = tf.shape(input_tensor)\n",
        "    batch_size = dyn_input_shape[0]\n",
        "    out_shape = tf.stack([batch_size, output_size, output_size, out_channels])\n",
        "    filter_shape = [filter_size, filter_size, out_channels, in_channels]\n",
        "    w = tf.get_variable(name=name, shape=filter_shape)\n",
        "    h1 = tf.nn.conv2d_transpose(input_tensor, w, out_shape, strides, padding='SAME')\n",
        "    return h1\n",
        "\n",
        "def conv2d(input_tensor, depth, kernel, name, strides=(1, 1), padding=\"SAME\"):\n",
        "    return tf.layers.conv2d(input_tensor, filters=depth, kernel_size=kernel, strides=strides, padding=padding, activation=tf.nn.relu, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}